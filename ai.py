# ai.py
# ============================================
#  üîä –ê—É–¥—ñ–æ ‚Üí Faster-Whisper (—É–∫—Ä–∞—ó–Ω—Å—å–∫–∞)
#  üñºÔ∏è –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è ‚Üí EasyOCR (—É–∫—Ä–∞—ó–Ω—Å—å–∫–∞)
# ============================================

from faster_whisper import WhisperModel
import easyocr
from PIL import Image
import numpy as np

# --- Faster-Whisper (–ª–æ–∫–∞–ª—å–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ) ---
_model = WhisperModel("small", device="cpu", compute_type="int8")

def transcribe_audio(file_path: str) -> str:
    """
    –†–æ–∑–ø—ñ–∑–Ω–∞—î —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –º–æ–≤—É –∑ –∞—É–¥—ñ–æ –ª–æ–∫–∞–ª—å–Ω–æ (–±–µ–∑ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç—É).
    """
    try:
        segments, _ = _model.transcribe(
            file_path,
            language="uk",
            vad_filter=True,
            beam_size=5
        )
        text = " ".join(seg.text for seg in segments).strip()
        return text or "(–ø–æ—Ä–æ–∂–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)"
    except Exception as e:
        return f"–ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó: {e}"


# --- EasyOCR (—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –∑ –∫–∞—Ä—Ç–∏–Ω–æ–∫) ---
_reader = easyocr.Reader(["uk"], gpu=False)

def extract_text_from_image(image_path: str) -> str:
    """
    –†–æ–∑–ø—ñ–∑–Ω–∞—î —Ç–µ–∫—Å—Ç —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –∑ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (–±–µ–∑ Tesseract).
    """
    try:
        img = np.array(Image.open(image_path))
        results = _reader.readtext(img, detail=0)
        text = " ".join(results).strip()
        return text or "(—Ç–µ–∫—Å—Ç –Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ)"
    except Exception as e:
        return f"–ü–æ–º–∏–ª–∫–∞ OCR: {e}"
